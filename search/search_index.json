{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to NAF Reference","text":"<p>A place to collaborate on reference architectures, reference frameworks, reference methodologies, just stuff to reference...</p>"},{"location":"#netdevops-primer","title":"NetDevOps Primer","text":"<p>The history and building blocks you need to know before you get started leveraging modern tools and methodologies to build and operate an intent based network (IBN).</p> <p>The NetDevOps Primer</p>"},{"location":"#framework","title":"Framework","text":"<p>TBD...</p>"},{"location":"#your-idea-here","title":"Your Idea Here","text":"<p>...Go nuts.</p>"},{"location":"Framework/Framework/","title":"The Network Automation Architecture by the NAF","text":"<p>This document outlines a modular, vendor-neutral framework for network automation. It defines a high-level reference model comprising key building blocks and functions necessary for designing, implementing, or refining automation strategies. The framework serves both as a starting point for new automation efforts and a guide for evolving existing solutions.</p>"},{"location":"Framework/Framework/#context","title":"Context","text":"<p>Network automation encompasses a wide range of use cases and infrastructure types, including on-premises, cloud, and hybrid environments. It covers everything from hardware provisioning and protocol configuration to performance monitoring and policy enforcement.</p> <p>This architecture defines functional building blocks that can be composed into tools. Rather than starting with specific tools, we advocate designing around required functionalities. Teams can begin with a narrow focus\u2014such as monitoring or automation\u2014and expand over time as needs evolve.</p> <p>All components SHOULD follow modern software engineering practices, such as version control and CI/CD, and expose machine-friendly APIs (documented via schema). This ensures seamless integration with internal systems and external tooling for security, logging, observability, and traceability.</p> <p>Moreover, all the blocks MAY be implemented by one or more components as needed. The blocks don\u2019t have to be a single instance; there could be many instances depending on the concrete implementation.</p>"},{"location":"Framework/Framework/#the-architecture","title":"The architecture","text":"<p>The proposed reference architecture defines six major functional building blocks (besides the actual network infrastructure), each with a clear and distinct purpose to enable straightforward mapping of specific features. While we acknowledge that some areas may overlap or require further refinement, our priority has been to establish a solid foundational understanding.</p> <p></p> <ul> <li>Intent: Defines the logic to handle and the persistence layer to store the desired state of the network, including both configuration and operational expectations.</li> <li>Observability: It persists the actual network state, and defines the logic to process it.</li> <li>Orchestrator: Defines how the automation tasks are coordinated and executed in response to events.</li> <li>Executor: Encompasses the actual tasks applied to the network to drive changes (e.g., updating configuration) as guided by the intended state.</li> <li>Collector:  In contrast to Executor, this component focuses on retrieving (i.e., reading) the actual state of the network.</li> <li>Presentation: Provides the interfaces through which users interact with the system, including dashboards, graphical user interfaces (e.g., ITSM), and CLI tools. </li> </ul>"},{"location":"Framework/Framework/#intent","title":"Intent","text":"<ul> <li>It MUST be capable of representing, in a structured form, any network-related aspect. This broad scope includes, but is not limited to, data such as IP addressing, data center infrastructure (e.g., racks, cabling), routing protocols, virtualized services, secrets, operational levels (such as maximum CPU), configuration templates or data mappings, and artifacts, as well as service abstraction or policy definitions. </li> <li>The data MUST support create, read, update, and delete operations. </li> <li>Access to this information MUST be exposed through a standardized, well-documented Application Programming Interface (API) (e.g., REST, GraphQL, etc.).</li> <li>The modeling SHOULD use a neutral representation that will be derived into vendor-specific configuration artifacts.</li> <li>It SHOULD provide a consistent and unified view of the desired state, even when the data is distributed across multiple data sources. </li> <li>In addition to the core network data, it SHOULD include metadata that supports effective data governance, such as timestamps, data origin, data ownership, and valid periods.</li> <li>Ideally, these operations SHOULD be transactional, offer custom validation, and provide a versioned access to data.</li> <li>It MAY include all the logic related to intended state management, such as data validation, data aggregation or replication, breaking down abstract services into concrete objects, and combining data to generate configuration artifacts.</li> </ul>"},{"location":"Framework/Framework/#executor","title":"Executor","text":"<ul> <li>It MUST be capable of interacting with any of the supported network write interfaces, including SSH, NETCONF, gNMI/gNOI, and REST APIs.</li> <li>It SHOULD support any network operation that alters the network state, such as deploying a full or partial configuration artifact or performing device actions like reboots and software updates.</li> <li>The task input SHOULD come from the intended state or be derived from it through data originating from the Observability component.</li> <li>It SHOULD provide a dry-run operation to check the expected result of the execution without actually executing it.</li> <li>It SHOULD support transactional execution of the changes.</li> <li>It MAY support both imperative approaches (where the task defines how to operate) and declarative approaches (where the task defines what the desired outcome is, and the system determines how to achieve it). In both cases, the operation SHOULD be idempotent; rerunning it should produce the same result.</li> </ul>"},{"location":"Framework/Framework/#collector","title":"Collector","text":"<ul> <li>It MUST includes capabilities for retrieving live data from the network using read interfaces\u2014similar to the Executor component\u2014but extends support to additional protocols to capture metrics and log, such as SNMP, Syslog, and other data such as flow-based telemetry (e.g., NetFlow, sFlow), packet capturing, traces, and others.</li> <li>The data values SHOULD be normalized from different vendors and method specifics.</li> </ul>"},{"location":"Framework/Framework/#observability","title":"Observability","text":"<ul> <li>It MUST support historical data persistence and offer powerful programmatic access to this data\u2014enabling advanced analytics, reporting, and troubleshooting workflows.</li> <li>It SHOULD offer a capable query language to extract the data.</li> <li>It SHOULD expose relevant insights into the current network state and automatically generate events when discrepancies are detected between the actual state (configuration or operational) and the intended state. These events MAY be processed by humans or connected to the Orchestration block to be automatically processed.</li> <li>Retrieved data MAY be enriched with contextual information from the intended state, including other third-party sources (e.g., EoL information, CVEs, maintenance notifications, etc.), enhancing analysis and enabling more accurate data correlation.</li> </ul>"},{"location":"Framework/Framework/#orchestrator","title":"Orchestrator","text":"<ul> <li>It MUST enable the coordination and integration of processes across the various building blocks, allowing the creation of more sophisticated and end-to-end automation workflows. It doesn't directly interact with the network infrastructure.</li> <li>Process execution SHOULD follow an event-driven approach, where events can be received synchronously, asynchronously, or generated on a scheduled basis.</li> <li>Execution logic SHOULD allow for reverse/compensating actions when a step results in an error or unexpected result, allowing for a controlled rollback. This may be hard to implement due to network infrastructure limitations.</li> <li>It SHOULD provide a dry-run operation to check the expected result of the workflow without actually executing it.</li> <li>It SHOULD provide the ability to schedule the execution of a workflow on a regular basis or at a given time in the future.</li> <li>It SHOULD provide end users with an understanding of the whole automation logging and traceability in the past and current workflows.</li> <li>It MAY include logic to correlate multiple events, infer relationships, and determine the appropriate course of action based on the event context.</li> </ul>"},{"location":"Framework/Framework/#presentation","title":"Presentation","text":"<ul> <li>It MUST provide robust and flexible authentication and authorization capabilities.</li> <li>This component MAY take various forms depending on the needs of the end user, including graphical user interfaces, ITSM, change management systems, messaging platforms, documentation portals, or reporting dashboards.</li> <li>It MAY support both read and write interactions, enabling users to view data, initiate tasks, or approve changes.</li> <li>It is designed to interface with any of the other building blocks as required, serving as the primary point of contact between humans and the automation system, but this does not imply the need for a single pane of glass.</li> </ul>"},{"location":"Framework/Framework/#contributors","title":"Contributors","text":"<ul> <li>Christian Adell</li> <li>Ryan Shaw</li> <li>Dinesh Dutt</li> <li>Claudia de Luna</li> <li>Damien Garros</li> <li>Wim Henderickx</li> </ul>"},{"location":"NetDevOpsPrimer/Automation/","title":"Automation","text":"<p>Much of what people are excited by when they first hear about SDN is actually network automation. As you may already know, automation is delegation to a bot. Just as you can delegate a task to another human, like making your kid mow the lawn; you can delegate a task, project, or result to some type of machine (a bot). In other words, automation is any technology that shifts work from humans to machines. A thermostat, for example, automates the temperature control of your home \u2013 it turns the heating or cooling on and off, so that you don\u2019t have to.</p> <p>Network automation, more specifically, is the act of offloading network operations to software tools. Theoretically you could build a robot to pull cables for you, but in practice it\u2019s software tools like scripts, programs, or applications that are most useful for automating your network. And almost every aspect of network operations can be automated.</p> <p>When most folks hear the words network automation they immediately think about provisioning. Turning up new ports. Configuring a customer or department VLAN. Adding firewall rules or ACLs, etc. And you\u2019d be right to think along these lines. Provisioning, and configuration change more generally is ripe for automation. Especially making simple changes across large networks. Why manually log in to dozens, hundreds, or especially thousands of network devices (/functions) to make a change when you can instead write a script to do that for you?</p> <p>Automation can be about more than making configuration changes though. In fact, it is often better to start your automation journey with read-only tasks. In traditional networks troubleshooting often takes up as much, if not far more time than configuration management. Anyone who\u2019s ever had to trace down a missing VLAN or MPLS statement knows this first hand. Automation can make root cause identification much simpler, and more scalable. What if instead of training every help desk employee how to track down various network issues you could provide them with a suite of tools pre-programmed to provide the needed information to them, or to the next tier of network operations center (NOC) personnel?</p> <p>Of course, providing these automation tools to more junior staff isn\u2019t just for troubleshooting. The same technique can level up your provisioning team as well. In some organizations, the architecture or engineering team provides changes to operational staff as pre-written scripts. The best of these include all the needed pre and post checks, along with the actual changes to be executed during a maintenance window (or whenever is appropriate for that change in that org). We can also take this a step further with event-driven automation that doesn\u2019t require any manual intervention at all; instead the network operates itself (to some degree).</p> <p>This is the promise of automation. Compounding the skills on your team to do more work with the same number of people by delegating as much as possible to the bots. An added benefit, when done right, is the reduction (and ultimate elimination) of downtime caused by human error. </p> <p>These promises are not always delivered though. Complete network automation is a massive undertaking, often involving thousands or tens of thousands of individual components (interfaces, vlans, protocols, devices, etc.). Failed or broken automation can create nightmarish \u201cfail at scale\u201d scenarios, where a bad change is propagated across a large network in an instant, sometimes causing massive outages. And building and coordinating the needed automations is still a manual task, although one with much greater leverage than device by device operations.</p> <ul> <li>Back: Software Defined Networking (SDN) </li> <li>Next: Orchestration</li> </ul>"},{"location":"NetDevOpsPrimer/Feedback/","title":"Feedback","text":"<p>It turns out that automation and orchestration have another thing in common. Both can operate in either an open-loop or a closed-loop fashion (with or without feedback). </p> <p>The terms open-loop and closed-loop can apply to various mechanical and/or electronic systems. The most applicable to our purposes here is their use in describing control systems. Strictly speaking, an open-loop control system is one in which the output does not impact the control action of the system. In contrast, a closed-loop control system, as you might have guessed, is one in which the output does impact the control action. Open-loop and closed-loop systems can also be referred to as non-feedback and feedback systems, respectively. </p> <p></p> <p>As you can see in the above diagram, an open-loop (or non-feedback) control system has no feedback loop. The timer function on a clothes dryer is a good example. The input in this case is the time you set after you load up your wet clothes from the washing machine. Once you close the door and hit start, the dryer runs for that amount of time. And then it stops. Whether your clothes are actually dry or not is of no consequence. To restate; the control function is completely independent from the output.</p> <p>Referring again to the diagram above, you can see that a closed-loop system does have a feedback mechanism. A common example is the thermostat in your home or office. This time the input is your desired temperature. The system then compares the desired temperature to the ambient temperature in the room and any difference is recorded as an error signal, which is then sent to the controller. The controller bases its control action on the error signal received. If the room is too hot, it activates the cooling system, and if the room is too cold, it activates the heating system. When either heating or cooling changes the ambient temperature in the room, this new temperature is compared to the desired temperature (the input), a new error signal is generated, and a new control action is taken. This continues until there is no error (when the room temperature matches the desired temperature). </p> <p>A more complex closed loop system can have multiple feedback loops to further refine control. The key observation is that output is fed back into the control system in order to provide more reliable and accurate control. This is how multitudes of industrial and other control systems avoid \u201cfail at scale\u201d and \u201crunaway automation\u201d problems.</p> <ul> <li>Back: Orchestration</li> <li>Next: Network Validation</li> </ul>"},{"location":"NetDevOpsPrimer/IBN/","title":"Intent Based Networking (IBN)","text":"<p>Intent Based Networking (IBN) is the abstraction of network management specifics into a common management plane (/interface). Unlike SDN, IBN doesn\u2019t try to invent new protocols, or replace the highly effective, distributed control plane inherent in our current routing protocols. Instead, IBN provides a single, declarative management plane. One interface to manage an entire network \u2013 no matter the scope or scale. And critically, this management plane is not only protocol agnostic (you can route however you wish), it is also device agnostic \u2013 meaning that IBNs can be heterogeneous networks made up of various makes and models of network devices and functions.</p> <p>The word \u2018intent\u2019 is clearly key to the concept of IBN. The definition of intend is (a) to have in mind as a purpose or goal (plan) and (b) to design for a specified use or future. Your intent is your desired outcome or end-state. And this idea of intent and intent-based anything \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 is tightly coupled with the idea of declarative models and declarative programming. This concept of declarative instructions is best understood by contrasting it with imperative commands/models/styles.</p> <p>Declarative statements describe what needs to be done while imperative statements define exactly how to do it. For example, a declarative request might be \u201cI want a lox bagel with cream cheese on my desk Monday at 10am.\u201d The corresponding imperative instructions would be along the lines of \u201cLeave home 20 minutes early on Monday, and during your commute, get off the subway at the Myrtle Avenue stop, go upstairs and cross the street, enter the Good Times deli, order a bagel with lox and cream cheese, wait for the person behind the counter to make the bagel\u2026 Etc.\u201d</p> <p>The example holds for technical network operations tasks as well. We have traditionally used an imperative style approach to configuring (and troubleshooting) our networks. From executing a specific command on the CLI, to writing a script that defines the exact steps needed to implement a needed change across the network, to documenting a method of procedure (MoP) that defines exactly what needs to be done and in what order to execute a network maintenance, imperative instructions permeate legacy network management techniques.</p> <p>IBN signals a shift from imperative network management to a declarative, network as code approach. Of course those individual steps laid out in imperative instructions still need to be completed. You can\u2019t have a lox bagel on your desk if no one buys it and puts it there. And you can\u2019t have a peering relationship between two networks if BGP is never configured. So how do we move from an imperative model of network management to a declarative, IBN model? We need a combination of abstraction and trust.</p> <p>Abstraction is a term we\u2019ve already used several times and it\u2019s worth looking at a bit deeper now. Unfortunately, for many, abstraction is an abstract idea. And formal definitions are not as straightforward a way to describe \u201cabstraction\u201d as they are for many other words. \u201cAbstract\u201d can be an adjective, a noun, and a verb - each with several meanings. Two of the most relevant are: \u201csomething that summarizes or concentrates the essentials of a larger thing or several things\u201d and \u201cto consider apart from application to or association with a particular instance.\u201d\u00a0</p> <p>In the context of networking, and computer science more generally, an abstraction is typically something that hides complexity from the user. Note that we said \u201chides\u201d and not \u201celiminates.\u201d As we mentioned earlier, someone (or something) still has to go get that lox bagel - you just don\u2019t need to know about it. From your perspective, when you hit the \u201clox\u201d button, a bagel simply appears on your desk.</p> <p>You can probably guess that this is where trust comes into play. In our delicious example, you need to trust that your assistant/messenger/delivery-person/whoever knows what a lox bagel is, where to find one, and how to get it onto your desk. By trusting that this person (or robot) knows how to get the task (or project) done, you remove the need to be involved in the details of every step. You free up your time to work on higher level, higher value work that is more suited to your individual skill set.\u00a0</p> <p>Moving back into the world of networking, an IBN-style centralized management plane provides you with a declarative interface by abstracting the imperative details required to execute on your intent. As long as you can trust the system to carry out your orders, you need not concern yourself with those details. Of course, those detailed commands are hidden, not eliminated, and so it\u2019s slightly more complicated than that. How complicated depends on who you are in this process. Here\u2019s a simplified breakdown of some common roles and how they interact with an IBN:</p> <ul> <li> <p>IBN Developer - Creates, builds, and deploys the management plane that operates your entire network as one distributed system, defined by code. They need to intimately understand the network at the component level in order to interpret declarative statements into function specific imperative commands.</p> </li> <li> <p>IBN Architect - Creates and builds modular configuration templates that define the operation of the network at a functional role level. They need to intimately understand the desired network architecture and the discrete functions needed to operationalize it by defining policy as code. E.g. how will edge routers operate, how will stateful firewalls operate, etc. They do not need to understand the specifics of device configuration, as that is handled by interpreters written by the IBN Developer.</p> </li> <li> <p>IBN Engineer - Manages network growth and change within the defined system architecture. They need to understand both the network architecture and the software systems that operate it. These engineers will ensure that the IBN works as needed through capacity planning, hardware provisioning, deploying new functions and/or functionality, handling escalations from operators and users, and escalating to architects or developers as needed for larger or more fundamental changes.</p> </li> <li> <p>IBN Operator - Manages the day to day operation of the network as a distributed system. They need to understand the basics of networking in general, the network architecture in use, and the functionality of the management plane. This category often includes several distinct roles or tiers depending on the type of business and the purpose of the network. Troubleshooting is a key function of these teams, however they perform this service through the management plane and should not ever need to \u201clog in\u201d to a specific network device or function.</p> </li> <li> <p>IBN User - This is a defining characteristic of IBN because a properly constructed management plane makes it possible for nearly anyone to interact with the network as an abstracted and distributed system that provides connectivity to users and applications. They only need to understand the desired business intent and the declarative model used to instantiate that intent. Users could be a provisioning team, a developer, or even an application itself. In advanced IBNs some users may be bots themselves, triggering network actions based on events as they transpire (event driven automation). They may also include executives and managers who need visibility into network operations.\u00a0</p> </li> </ul> <p>Another way to think about IBN is as the convergence of SDN, automation, orchestration, closed-loop feedback, validation, and IaC. In other words, an IBN is a network that applies everything we\u2019ve learned so far to design, build, operate, and upgrade the network as a distributed system providing connectivity how and where needed across your business. In this context IBN is the most modern evolution of network operations methodologies, and the ultimate evolution of many of the ideas born with SDN.</p> <p>The multi-vendor management plane provided by IBN allows for repeatable and assured operations, which ultimately leads to a more reliable network and a faster time to market for new network enabled products and services.</p> <ul> <li>Back: Infrastructure as Code (IaC)</li> <li>Next: NetDevOps</li> </ul>"},{"location":"NetDevOpsPrimer/IaC/","title":"Infrastructure as Code (IaC)","text":"<p>And that brings us to Infrastructure as Code (IaC). IaC is a concept from datacenter virtualization and especially cloud and DevOps that makes things repeatable, automatable, and verifiable by leveraging abstraction and flipping the source of truth.</p> <p>Just like virtualization, the \u201cserver folks\u201d (or more accurately the developers) got here first. In many ways, IaC is the natural outgrowth of server virtualization. Today, turning up a server usually means creating a VM, a container, or multiple of either. And of course that is done not by physically racking and connecting a device but by typing some commands into a VMware, AWS, GCP, Azure, or other management interface. These commands are now creating your infrastructure.</p> <p>This is an abstraction - of course there must still be hardware underneath. The dirty little secret of software is that it all runs on hardware. But in the cloud, as well as any properly provisioned and virtualized data center environment, we can now assume that the basic HW requirements are present. That frees us to use commands to apply the available resources as needed for our application. Of course, instead of typing the needed commands into a user interface, we can leverage APIs, declarative definition files, version control systems (such as Git), and automation tools to do it all with code.</p> <p>From a developer perspective, this makes complete sense. It\u2019s exactly how software has been written for decades. And that\u2019s kind of the point. One of the fundamental principles of DevOps is to treat infrastructure the same way developers treat applications. When the infrastructure is defined by software (code), you can then treat that software as you would any other development project. Ideally, it actually becomes part of the development project. The files defining the needed infrastructure ride along with the files defining the application. And just as the same source code always produces the same binary, the same infrastructure definitions always create the same environment.</p> <p>This highlights one of the key advantages of IaC - repeatability. By defining the needed infrastructure (such as virtual machines, containers, load balancers, firewalls, network topologies, etc.) as code, we can ensure that every developer is working in the same environment that their application or feature will eventually be deployed into. We are not managing the infrastructure device by device, or even environment by environment; we are defining it once, and applying that definition everywhere it is needed. This level of repeatability is referred to as being idempotent.\u00a0\u00a0</p> <p>That, combined with its other two primary advantages (automatability and verifiability) are what make IaC a needed component in continuous integration, continuous delivery, and ultimately continuous deployment (collectively CI/CD). Because it provides a standardized, idempotent definition of the needed environment, deployment of that environment can be performed automatically with tools like Chef, Puppet, SaltStack, Ansible, or Nornir. And because it\u2019s defined with standardized declarative code, the environment can always be validated against its definition. In fact, you can perform automated verification (/validation) both pre and post deployment - just as developers do with their application code.</p>"},{"location":"NetDevOpsPrimer/IaC/#network-as-code","title":"Network as Code","text":"<p>How do we apply this concept of IaC to networking? Well, as you may have noticed above, in many cases we already have. For cloud-native applications being built, tested, and deployed completely within a public (or private) cloud, the basic networking requirements are almost certainly part of the IaC being developed and maintained along with the application. But most networks are far from this potential ideal state. So, how do we get there?</p> <p>There are a few basic requirements needed to implement our network as code (NaC). First, we need a stable, physical network with plenty of capacity and redundancy. Next we need to leverage network virtualization and network function virtualization to abstract the overlay networks we want from the underlay networks we need. Then we need to move our source of truth from the on-device configuration text to a centralized repository leveraging version control. And finally, we need a tool to push accepted configuration changes from that repository out to all of the devices and functions that make up the network.</p> <p>A key to making this work is a personal, mental paradigm shift. We can no longer think about changing the configuration on a specific device. To leverage NaC we need to think of the network as a distributed system that is controlled by the declarative definition files managed through our version control system. If I want to change the behavior of the network, I never log into one or more devices directly. Instead, I just change the code that defines the network and then use an automation tool to push my (approved) changes out to all of the devices and functions that need to be updated, all at once.</p> <ul> <li>Back: Network Function Virtualization (NFV)</li> <li>Next: Intent Based Networking (IBN)</li> </ul>"},{"location":"NetDevOpsPrimer/NFV/","title":"Network Function Virtualization (NFV)","text":"<p>If network virtualization is all about virtualizing networks, then network function virtualization is all about virtualizing\u2013you guessed it\u2013network functions. But what exactly are network functions, and why would we virtualize them?</p> <p>In traditional, legacy networks we often define the network through the included devices and the connections between them. We might say that a particular network is made up of seven switches and one router connected in a ring topology. Or that we have 6 routers connected in a full mesh, etc.</p> <p>The problem with this perspective is that it tends to miss both the forest (the whole network as a distributed system) and the trees (the individual and distinct components of that system). This is because devices themselves are subsystems of the overall network system. And they in turn are collections of various hardware and software components. Those same individual and distinct components are what determine how the network works.</p> <p>For example let\u2019s consider a common and simple function; the ACL. Short for access control list, an ACL is essentially a policy statement that when enforced affects a stateless firewall. In a device-centric view of the network we may perceive that our 6 routers each have their own ACL configured to protect (for example) the control plane; this perception leads us to separately manage 6 ACLs in the network. However, if we take a function-centric view of the network we would perceive instead that there should only be a single ACL, written and updated once for the entire network, and then applied within 6 routers.</p> <p>Independently creating 6 distinct ACLs for the same purpose in the same network is inefficient and error prone. Crafting a single ACL to meet our needs and then applying it 6 times removes the extra work and much of the risk. Many network engineers already work this way, and have for decades. Who was the first to copy a bit of configuration into a text editor, make changes, and then copy and paste the updated stanza to multiple devices? We may never know - but we can safely assume it was done quite some time ago.</p> <p>Modern network function virtualization (NFV) goes beyond this. Today, NFV is all about disaggregating all of the jobs performed from any specific network hardware. Each role, each purpose is instantiated in software, divorced from any specific hardware. For another example, think about the difference between a switch and a router. These days, that line feels more and more blurry. That\u2019s because we\u2019re often conflating the physical device (a switch) with a software function (the routing daemon).</p> <p>In the past this distinction was very hard to make, because network gear was only sold packaged as monolithic packages of hardware and software. Imagine an iPhone with no app store. Apple provides the hardware and software packaged together and you have no options other than what Apple makes available. You can replace the firmware wholecloth with a new version but you have no choice in what features are or are not included. This is how all the major networking vendors operated for a long time.</p> <p>More recently, a wave of disaggregation has swept across the industry. This wave has been building for some time. In 1996 the GNU Zebra project was started. The project created the world's first open-source software routing engine. While that project was discontinued in 2005, it lives on, having been commercialized by its creators as ZebOS and also forked into another open source project, Quagga (named for an extinct subspecies of the African zebra). Quagga has since been forked into the Free Range Routing (FRR) software suite. BIRD (the BIRD Internet Routing Daemon) is another popular open source software routing engine used by internet exchanges and others around the world. These packages, along with several others, make it possible to run a \u201crouter\u201d on any UNIX-like (Linux, BSD, etc) operating system.</p> <p>The cumulative effect is the disaggregation of hardware and software for networking. These projects all provide a routing function that can be used independent of any specific hardware. Of course, routing isn\u2019t the only function we can disaggregate from hardware, and disaggregation does not require open-source software. These days many proprietary network functions are also available (virtualized) as software.</p> <p>This can be a full, proprietary network operating system (NOS) that runs in a virtual machine (VM) or a container. It can also be a more specific function, like routing, Ethernet switching, firewalling, load balancing, or essentially any other network objective. And this disaggregation can be leveraged in at least two broad methods.</p> <p>First, disaggregation provides the ability to \u201cmix and match\u201d network hardware and software. Using just the functions you need, from software packages you trust, on the hardware of your choice. Imagine running FRR on a big vendor\u2019s router or switch, or running that vendor\u2019s NOS on a third-party (commodity) bare metal switch. </p> <p>Second, disaggregation allows you to run these functions purely as software within your datacenter or cloud infrastructure. Think of running BIRD in a container on commodity server hardware, and of all the networking functions provided by a public cloud operator (or in a kubernetes cluster).</p> <p>The upshot is that virtualized network functions (VNFs) can be run exactly where you need them, with whatever resources (compute/memory/storage) needed, often independent of specific physical devices. While we will always need hardware switches to push packets physically around the network, in most cases it is more efficient to move network software into discrete functions. Among the benefits already mentioned, this allows us to limit our attack surface (by not running features or functions that are not required) and enables easier upgrades (by separating the bits needing to be upgraded). It can also allow us to use the same software for these functions whether they are instantiated on physical network devices, within our own virtualized or containerized environments, or across public cloud infrastructure.</p> <p>Just as network virtualization abstracts our network topology from the physical network connections, NFV abstracts our network architecture from the physical network devices.</p> <ul> <li>Back: Network Virtualization</li> <li>Next: Infrastructure as Code (IaC)</li> </ul>"},{"location":"NetDevOpsPrimer/NetDevOps/","title":"NetDevOps","text":"<p>NetDevOps is a methodology that applies DevOps practices to networking. DevOps, known for its principles of continuous integration, continuous delivery (CI/CD), Infrastructure as Code (IaC), and the software development life cycle (SDLC), has transformed software development. Now, these principles are being adapted to network operations, bringing efficiency, agility, and automation to the fore.</p> <p>NetDevOps is how you build and operate an IBN.</p> <p></p>"},{"location":"NetDevOpsPrimer/NetDevOps/#key-components-of-a-successful-netdevops-practice","title":"Key Components of a Successful NetDevOps Practice","text":"<p>To build a successful NetDevOps practice, you need more than just a team of smart, hardworking individuals. Here are the essential components:</p>"},{"location":"NetDevOpsPrimer/NetDevOps/#1-centralized-off-device-datastores","title":"1. Centralized (Off-Device) Datastore(s)","text":"<p>These data stores are often referred to as \"Source(s) of Truth\"</p> <p>You know the challenges inherent in managing your network configurations with bits and pieces of information scattered across various devices. It\u2019s chaotic, to say the least. That's why having centralized, off-device sources of truth is crucial. These databases and repositories hold the definitive versions of all network configurations, templates, and specific data.</p> <p>With centralized sources of truth, you can:</p> <ul> <li>Ensure consistency across your network.</li> <li>Easily track and manage changes.</li> <li>Quickly revert to a known good state if something goes wrong.</li> </ul>"},{"location":"NetDevOpsPrimer/NetDevOps/#2-configuration-validation-engine","title":"2. Configuration &amp; Validation Engine","text":"<p>Next up is the configuration and Validation engine. This component is responsible for managing the state of your devices and functions. It ensures that configurations are not only applied correctly but also validated against predefined policies and standards.</p> <p>A robust configuration and validation (aka Orchestration) engine allows you to:</p> <ul> <li>Automate the deployment of configurations.</li> <li>Validate changes before they are rolled out.</li> <li>Detect and rectify configuration drift, where actual device states diverge from the intended states.</li> </ul>"},{"location":"NetDevOpsPrimer/NetDevOps/#3-operational-toolkit","title":"3. Operational Toolkit","text":"<p>Finally, no NetDevOps practice would be complete without a comprehensive operational toolkit. This toolkit includes tools for monitoring, reporting, and troubleshooting your network.</p> <p>With the right operational tools, you can:</p> <ul> <li>Go beyond monitoring and provide true Observability.</li> <li>Generate detailed reports on network health and performance.</li> <li>Quickly identify and resolve issues, minimizing downtime and maintaining optimal network performance.</li> </ul>"},{"location":"NetDevOpsPrimer/NetDevOps/#bringing-it-all-together","title":"Bringing It All Together","text":"<p>Implementing NetDevOps is not just about adopting new tools and practices; it\u2019s about changing the way you think about and manage your network. It requires a cultural shift towards automation, continuous improvement, and collaboration between development and (network) operations teams.</p> <p>Here\u2019s a quick recap of what you need for a successful NetDevOps practice:</p> <ul> <li>The Right Team: Combine the talents of software developers, systems engineers, and network engineers.</li> <li>Centralized Datastore(s): Keep your configurations consistent and easily manageable.</li> <li>Configuration &amp; Validation Engine: Automate and validate your network configuration changes.</li> <li>Operational Toolkit: Monitor, report, and troubleshoot effectively.</li> </ul> <p>By embracing NetDevOps, you can transform your network operations, making them more efficient, reliable, and scalable. It's time to take the leap and bring the power of DevOps to your networking domain.</p> <ul> <li>Back: Intent Based Networking (IBN)</li> </ul>"},{"location":"NetDevOpsPrimer/NetDevOpsPrimer/","title":"The NetDevOps Primer","text":"<p>The history and building blocks you need to know before you get started leveraging modern tools and methodologies to build and operate an intent based network (IBN).</p> <p>AKA: An Introduction to Network Automation 3.0</p> <p>Original contribution from Chris Grundemann, funded by FullCtl.</p>"},{"location":"NetDevOpsPrimer/NetDevOpsPrimer/#the-evolution-of-network-operations","title":"The Evolution of Network Operations","text":"<p>In the beginning, there was the CLI, and for a (long) time the CLI was good (enough). But networks have grown and evolved since those early days. Not only have they gotten larger and more complex, networks have also become ever more critical to our lives \u2014 and our businesses. This has ushered in an evolution of network operations as well.</p> <p>The first glimmers of this evolution started in the service provider networks, which became larger and more critical earlier than other networks. In the internet service provider (ISP) and network service provider (NSP) world, it has been common to use scripts to manage portions of the network for at least a couple of decades. In many cases network devices lacked proper Application Programming Interfaces (APIs) and so the earliest scripts simply logged in and executed CLI commands. These scripts made the job of managing large networks much easier, but they were obviously not the ultimate pinnacle of NetOps technology.</p> <p>Networks continued to evolve, and in parallel we saw the rise of server virtualization and the beginnings of \u201cthe cloud\u201d and hyper-scale data centers. Against this backdrop, OpenFlow was released in 2011. While that protocol was not quite the disruptive force many of us thought it might be, it did bring the concept of software-defined networking (SDN) into the fore. The basic premise of SDN is the complete separation of control and forwarding planes \u2014 which isn\u2019t necessarily a great idea, but it captured our imagination for other reasons.</p> <p>We were starving for a better way to manage our growing networks, and the idea of using software and automation to force multiply talented network engineers was, and still is, an attractive one. Today enterprise, data center, edge, and other networks have caught up to or even surpassed the size and complexity of SP networks, which caused the spread of this idea among even more networking professionals.</p> <p>The only problem is that SDN failed to really materialize. It was talked about, and it made its way into many vendors\u2019 slide decks, but it wasn\u2019t real. At least not in the way we wanted it to be.</p> <p>Enter intent-based networking (IBN) \u2014 the most modern iteration of network operations methodologies, and the ultimate evolution of many of the ideas born with SDN. Rather than try to invent new protocols or replace the highly effective, distributed control plane inherent in routing protocols, IBN provides a single management plane. One place to manage an entire network \u2014 no matter the scope or scale. And critically, this management plane is not only protocol-agnostic (you can route however you wish), but also device-agnostic \u2014 meaning that you can use IBN in a heterogeneous environment.</p> <p>The multi-vendor management plane provided by IBN allows for repeatable and assured operations. This ultimately leads to a more reliable network and a faster time to market for new network-enabled products and services. IBN is the foundation for NetDevOps and thus the future of networking.</p>"},{"location":"NetDevOpsPrimer/NetDevOpsPrimer/#interrelated-networking-concepts","title":"Interrelated Networking Concepts","text":"<p>Before starting to build and operate an IBN and NetDevOps practice, it\u2019s worth casting your gaze across the network operations landscape to better understand several interrelated concepts, trends, and methodologies. Now that we\u2019ve covered the history above, the remainder of this paper will help us do exactly that. Let\u2019s dive in:</p> <ol> <li>Software Defined Networking (SDN)</li> <li>Automation</li> <li>Orchestration</li> <li>Feedback</li> <li>Network Validation</li> <li>Network Observability</li> <li>Network Virtualization</li> <li>Network Function Virtualization (NFV)</li> <li>Infrastructure as Code (IaC)</li> <li>Intent Based Networking (IBN)</li> <li>NetDevOps</li> </ol>"},{"location":"NetDevOpsPrimer/NetworkObservability/","title":"Network Observability","text":"<p>In many ways, observability is a measure of validation. At its best; network observability is the capacity to easily answer any question about your network, right now. The easier it is to answer your questions (to validate your network), the better your observability. Furthermore, observability is not monitoring. Monitoring focuses on known unknowns, it watches for things we know to watch for (like high or low interface utilization), typically with the goal of alerting us when they happen. Observability on the other hand focuses on unknown unknowns, on being able to answer questions we didn\u2019t know we were ever going to ask at all.</p> <p>While this concept of observability is quite novel and abstract for many folks, it isn\u2019t new. Like most of the terms already covered, observability too is borrowed. It originally comes from control systems engineering and more recently has become a hot topic in software engineering. To understand it better, we\u2019ll start with the Wikipedia definitions: \u201cObservability is a measure of how well internal states of a system can be inferred from knowledge of its external outputs.\u201d and \u201cA system is said to be observable if, for every possible evolution of state and control vectors, the current state can be estimated using only the information from outputs.\u201d</p> <p>All that really says is that observability means understanding how a system works by observing it. It allows you to \u201cdetermine the behavior of the entire system from the system's outputs.\u201d In physical systems, these outputs are typically information gleaned from sensors. Think of the thermometer (sensor) telling us the temperature of the room (output) in our example above. In software systems, the outputs can come from almost anywhere and traditionally include logs, metrics, and traces; although more modern approaches tend to use additional and different outputs.</p> <p>The reason behind the rise of observability as a hot topic in software development is the ongoing move to ever more distributed systems. Service oriented architectures, virtualization, microservices, and containers are all similar in that they have made software applications more distributed and thus more complex. This is interesting because networks are inherently complex distributed systems. And that means that we should be really excited about observability too. It just requires that we think of our networks as systems, instead of as collections of links, devices, and functions.</p> <p>When most of us remember the last time we had to troubleshoot a network problem, it\u2019s very likely that the first thing we did was log into a network device. Step two is often running a bunch of show commands. And step three is logging into the next device, as indicated by what we learned from the first device. While this is an example of network validation, it is also an example of low or poor observability. Using this approach makes it quite hard to answer our fundamental questions: Is there something wrong with the network? What is wrong with the network? And ultimately; what do I need to do to fix it?</p> <p>To make a network more observable we need to regularly (automatically) pull data (outputs) into a central repository. Then, from this central location we need to be able to analyze all of the data at once and on-demand, whenever we need (or want) to. We should also store historical data so that we can ask questions about the past, compare current and historical state, or deal with change and trends more generally. </p> <p>Luckily, we have an advantage in all of this over physical systems in that we can actually pull data about state directly from the devices and functions. If you want to understand the state of a crane arm, for example, you must attach and calibrate a sensor to track and report its position. But if you want to understand the state of an interface, you can pull its status directly from the switch, router, firewall, etc. We don\u2019t need to infer or estimate the internal state of the system, we can collect control plane state directly, making this data the most important to have when it comes to network observability.</p> <p>Finally, it is worth noting that: \u201cIn control theory, the observability and controllability of a linear system are mathematical duals.\u201d Which means that, at least according to mathematical theory, the more observable a system is, the more controllable it is - and the more controllable a system is, the more observable it is. We alluded to this a bit above, and will dive deeper into the concept below, when we talk about intent. For now we can just meditate on the words of a pioneer of observability in distributed systems, who said that \u201cobservability is about understanding performance from the perspective of the user.\u201d</p> <ul> <li>Back: Network Validation</li> <li>Next: Virtualization</li> </ul>"},{"location":"NetDevOpsPrimer/NetworkValidation/","title":"Network Validation","text":"<p>Validation is the feedback we need when automating and orchestrating a network. The definition of validation that we are most concerned with here is \u201cto support or corroborate on a sound or authoritative basis.\u201d Breaking that down we can see that validation is all about authoritative corroboration. In other words we want to know for sure that what we believe is actually true.</p> <ul> <li>In networking terms, validation can be as simple as checking to ensure that the configuration on any given device matches the expected configuration. More advanced network validation will tell us if the behavior of the network matches the expected or desired behavior. In this way, validation can be seen as answering questions about your network. Questions such as:</li> <li>Is the network (still) connected and configured inline with the documentation? </li> <li>Is traffic between two nodes taking the expected path, with the expected latency? </li> <li>Is this proposed change safe to make on our production network? </li> <li>Is the change I just made having the intended impact?</li> </ul> <p>These are just a handful of examples. They should illustrate, however, some of the potential scope of network validation. We can break this scope out onto three axes; what is being validated, how it is being validated, and when it is being validated.</p> <p>Starting with \u201cwhat\u201d there are three categories; unit testing, functional testing, and formal verification. Unit testing looks directly at the configuration (in whole or in part) of a device or function. Unit testing can tell you things like whether an interface MTU is wrong, a VLAN is missing, or that an unexpected static route is now in place. Ideally you have a \u201cgolden\u201d or expected configuration to refer to (more on that later). If not, you may simply test against previous versions of the configuration to spot changes or \u201cdrift\u201d over time.</p> <p>Functional testing looks at behaviors, rather than configurations. Every network engineer has used ping to validate connectivity or traceroute to validate the routing path. This is functional testing. Much more advanced functional testing can be accomplished with emulators and model-based simulators, which we\u2019ll cover shortly. For now we can say that functional testing validates network behaviors within specific scenarios.</p> <p>Formal verification is an area of computer science based on mathematical rigor. In practical terms, we can think of it as super-functional-testing. Where functional testing validates subsets, like the path of a single flow or packet; formal verification looks at supersets, such as all possible flows and packets. Another way to state this is that tools like ping and traceroute sample how the network responds within specific test cases while formal verification proves that the system will always behave in a certain way, in all cases.</p> <p>How the validation happens is just as important. The simplest and most common ways to perform network validation are analyzing text or operational state. More advanced methods leverage emulation or model-based analysis. </p> <p>Text based analysis is typically used for unit testing, where we validate that one configuration or command matches another. Operational state analysis, on the other hand, looks at the effects of configurations - aka network (or at least device/function) behavior. For example you may validate the number of established BGP peers before and after a maintenance window; or even more simply, did that new BGP peer come up at all?</p> <p>Emulation is what we do in a network lab, whether physical, virtual, or a hybrid. Ideally our testbed mirrors the production network exactly. This allows us to validate the effects and impacts of changes in a controlled environment before we apply them in production. In reality there are many constraints that often restrict us from a perfect full-scale replica, which limits our ability to predict outcomes to the degree that the test environment differs from the production environment. We can contrast this with model-based analysis, which sidesteps the emulation challenges by simulating network behavior, often through abstract mathematical methods. Formal verification requires such a model-based approach. The possible pitfall here is accuracy as model-based network validation relies wholly on the data provided to build the model.</p> <p>The third and final axis of network validation scope is when it takes place. Here there are really only two options; before you make a change to the network, or after changes are made to the network. The common terms are pre-deployment and post-deployment. By definition then, post-deployment checks are reactive and pre-deployment checks are proactive. The former catches errors after they are in production while the latter aims to catch them before they can ever have an impact on production traffic. Both are valuable.</p>"},{"location":"NetDevOpsPrimer/NetworkValidation/#validation-automation","title":"Validation + Automation","text":"<p>You can have validation without automation. But they complement each other very well. This combination can work in two ways. The one that you may already be guessing at is using validation to control automation (and orchestration). This is using validation as a feedback mechanism to influence the actions of your automated and orchestrated network control system. We\u2019ll look at this in more detail in the IBN section, below.</p> <p>The other way to combine automation and validation is to automate your validation. Applying the tenets and tactics of automation and orchestration to network validation can ensure that you always know what you need to know. That means that errors are caught sooner, often even before they are made. This automated validation can of course be used to tame your orchestrated network control system as an enhanced feedback mechanism. It can also be used to inform you, the network operations teams, and anyone else in the business who might need to know the current (or past) state of the network. In either case, it is a direct antecedent to network observability.</p> <ul> <li>Back: Feedback</li> <li>Next: Network Observability</li> </ul>"},{"location":"NetDevOpsPrimer/NetworkVirtualization/","title":"Network Virtualization","text":"<p>Network virtualization is one of those topics that can seem very complicated when we encounter it out of context, but is actually well understood and even mundane to most network engineers. Network virtualization is the act of using tunnels to build overlay networks with topologies that are independent of the underlay network. As stated, it sounds intimidating. So we\u2019ll take a couple examples to demystify that definition. </p> <p>Let\u2019s start with the obvious; VLANs. VLAN stands for Virtual Local Area Network. That\u2019s right, if you have configured a VLAN then you have created a virtual network. It\u2019s worth going a bit further down the rabbit hole though, because in reality almost all networks are virtual networks.</p> <p>Think about the OSI model. While it is not a perfect representation of how systems actually work, there are some fundamental truths included within it. We do build networks in layers, even if we don\u2019t always think about it that way. And what\u2019s more, each of these layers builds upon the one below it by adding encapsulation, aka tunneling.</p> <p></p> <p>Consider the three figures in the diagram above. On the left we illustrate the physical connectivity of 8 nodes connected one to another in a ring. The middle figure illustrates the same network, but now shows the any-to-any mesh connectivity at the Ethernet layer. And remember that Ethernet is an encapsulation, adding a header to data to create frames. Finally on the right is an illustration of the IP (internet protocol) connectivity from all nodes to the single router - our network\u2019s default gateway. Here again, the difference between \u201clayer 2\u201d and \u201clayer 3\u201d is manifest in the IP header that turns frames into packets.</p> <p>This is a simplified example. Still, you should be able to extrapolate its lesson out into real world networks. Consider the classic three tier architecture of a campus network, with switches physically located in IDFs and MDFs throughout a building, or even multiple buildings. And \u201cabove\u201d that we can overlay an Ethernet network divided by VLANs to contain each department\u2019s data - multiple meshes riding over the physically hierarchical topology. And at the IP layer, those individual meshes are revealed to be hub and spoke networks, often tied to the same gateway router.</p> <p>Of course this is true not just for LANs, but also for WANs, MANs, WLANs, and essentially every computer network ever built. And it\u2019s not limited to MAC/PHY, Ethernet, and IP either. We can easily add in new layers, new encapsulations, and therefore new overlays and underlays (overlay just means the top layer being considered and underlay the layer beneath it - most underlays are also overlays, etc.). Using MPLS, VXLAN, or GRE to create tunnels are all methods of network virtualization. The key point is that through creating a virtual network overlay you can build any arbitrary network topology over the top of any other.</p> <p>This is important for many reasons. Chief among them is that it allows you to optimize each layer, each virtual network, for its specific purpose. At the physical layer we can build a network with the right capacity and latency where the most, or the most important traffic actually flows. At the Ethernet layer we can use VLANs to segregate traffic for storm-control, security, and privacy purposes; with broadcast traffic freely permitted inside those boundaries. And at the IP layer we can stitch these VLANs back together through specific traffic inspection points, while also connecting them to other, more far flung destinations by designing for optimal routing paths.</p> <p>When you combine network automation with network virtualization we open up new possibilities. Because virtual networks are created entirely in code (configuration) and leverage pre-existing physical connectivity; they can be turned up and turned down rapidly. And because automation and orchestration can make complicated and complex operations easier and simpler; they allow manipulation of virtual networks on a scope, scale, and speed far beyond what human operators can. Imagine a network that automatically provisions and de-provisions virtual links as they are needed and discarded by employees, customers, sensors, and applications. This is possible - and we\u2019ll show you how.</p> <ul> <li>Back: Network Observability</li> <li>Next: Network Function Virtualization (NFV)</li> </ul>"},{"location":"NetDevOpsPrimer/Orchestration/","title":"Orchestration","text":"<p>Some of the challenges introduced by automation can be addressed through orchestration. In fact, orchestration can best be conceptualized as the automation of automation. This can force multiply automation in ways similar to how automation multiplies individual human effort. And there are further benefits as well. Unfortunately, this concept of \u201cautomating automation\u201d can invoke images of matryoshka dolls, or worse, incomprehensible complexity and recursion. It is informative therefore to consider the origin of the term \u201corchestration.\u201d </p> <p>Perhaps obviously, this term is borrowed from the world of music. More specifically, it refers to the writing of music for an ensemble of instruments, most typically an orchestra. In this traditional usage, orchestration is the assignment of various parts of a musical work to the different musical instruments that will ultimately play each portion of a given composition. A simplistic example is the assignment of the melody to the strings section and the baseline to the percussion section. In reality musical orchestration is much more involved. Often a single chord is broken into its constituent notes, with each note assigned to a specific instrument.</p> <p>Bringing this back to the world of computer networking, we can say that automation is the delegation of a single task to a single bot, while orchestration is the outsourcing of an entire process to a team of bots. Just as a musical orchestrator can take a piece of music written for a soloist and adapt it to be played by a band or a full orchestra, a network orchestrator can take a common process or workflow and break it out into the required string of individual tasks. Each task (or set of tasks) is then assigned to the device or function that must execute it, in concert with other network components. This coordination and synchronization of multiple devices, systems, services, applications, and automations in order to execute a larger workflow or process is what we mean by orchestration.</p> <p>As we\u2019ve already seen, orchestration, like automation, is not a network specific construct. We can find the human embodiment of orchestration in coaches, gamemasters, and project managers. And within computer science we can find orchestration in various domains and at multiple levels. Service orchestration, container orchestration, application orchestration, cloud orchestration, and security orchestration all function similarly to network orchestration. What\u2019s more is that these various forms of orchestration can be tied together to meet even larger and more complex objectives. Orchestrating orchestration? Yes, it\u2019s turtles all the way down.</p> <ul> <li>Back: Automation</li> <li>Next: Feedback</li> </ul>"},{"location":"NetDevOpsPrimer/SDN/","title":"Software Defined Networking (SDN)","text":"<p>While the words \u201csoftware defined networking\u201d could be interpreted literally to mean any networking defined by software, the term and its acronym \u201cSDN\u201d were coined to refer to something far more specific. The concept that SDN is commonly accepted to name is defined by the complete separation of control and forwarding planes. </p> <p>In a typical network, control is provided by device configurations (which capture the operator\u2019s intent) and routing protocol messages (which coordinate forwarding paths between devices). Since routing protocol messages are transmitted between devices over the same physical and logical networks as any other data (routed protocol messages), there is some mixing of the control and forwarding planes. More so, the devices that are responsible for forwarding are complicit in choosing (controlling) those forwarding paths based on their individual configuration and operational state. Every network device is thus a controller and a forwarder. </p> <p>With SDN, on the other hand, device based configurations and routing protocol messages are not the primary source of control. Instead, there is a centralized controller which collects telemetry and mandates forwarding paths through an out of band (OOB) control channel to an API on each device (the OpenFlow protocol defines such an API along with the required message formats). In this way, control of network forwarding is totally decoupled from the forwarding function itself. The controller controls and the forwarders (network devices and functions) forward.</p> <p>The primary advantages of SDN are twofold, and both relate to the centralized control over the network that is the cornerstone of the concept. First, by moving control to a centralized function we provide a single point of management for the network. No longer do you need to login to individual forwarding devices (or functions) to troubleshoot issues or to make configuration changes. With SDN you have a centralized interface (provided by the controller) that delivers complete visibility and control over the entire network. </p> <p>Second, this centralization of control also provides theoretically limitless processing power. Rather than being reliant on, and constrained by the CPU and storage fitted into each forwarding device (switch/router/firewall/etc) the SDN controller is an application that can run on whatever server hardware or cloud platform you deem necessary. This allows you to scale the resources available, as you would for any other application. It also allows you to tie into virtually any data source. And all of that opens up possibilities for new and more advanced approaches to routing, policing, and otherwise controlling network traffic. In fact, the initial use case for OpenFlow was to allow researchers to try out new routing algorithms on production networks, without needing to swap out the forwarding device hardware or software.</p> <p>Additional, second and third order benefits accrue from these first two. Faster issue resolution due to centralized visibility and potentially powerful root cause identification lead to lower downtime. More agile policy and configuration management due to centralized control and potentially powerful automation and orchestration lead to faster time to market for new network enabled services. This is where things can often get confused though. Many of the benefits of SDN that folks tout are actually benefits of automation, orchestration, validation, and virtualization. To avoid confusion, we maintain the original and specific definition of SDN: The separation of the forwarding and control planes.</p> <p>When viewed from that narrow perspective, SDN is not strictly required for most benefits often attributed to it. And, like anything, it brings some challenges of its own. The biggest of these is interoperability and backwards compatibility. While many claim that SDN allows for heterogeneous vendor-neutral networks, that is only true if all the devices and functions support a \u201cNorthbound\u201d API compatible with the selected controller. This was the promise of OpenFlow \u2013 an open standard API and set of message formats to allow the controller function to \u201ctalk to\u201d the forwarding functions across vendors, platforms, and operating systems.</p> <p>In practice, this never really materialized. It\u2019s a beautiful idea in a greenfield network, where you can install only OpenFlow (or some other network API) compatible devices and functions. But as any network engineer knows, greenfields are few and far between. In most cases we are expanding or advancing an existing network. At the very least we need to inter-operate with an existing network. So, while some vendors leveraged OpenFlow in their own proprietary solutions to some success, most folks moved on to find other, less restrictive ways to manifest the dreams ignited by the idea of SDN.</p> <ul> <li>Back: Introduction</li> <li>Next: Automation</li> </ul>"}]}